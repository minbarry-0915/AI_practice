{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM6FeUMZ8XQhqRhOqhHpdrs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minbarry-0915/AI_practice/blob/main/AI_HW6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sPkhcfmgsez",
        "outputId": "703038d3-7e87-4a5b-847b-a4a8f17add69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A =  tensor([[ 1., -1.],\n",
            "        [ 1., -1.]])\n",
            "B =  tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "C =  tensor([[0.8480, 0.0194, 0.5425],\n",
            "        [0.3343, 0.1450, 0.2286],\n",
            "        [0.2310, 0.7569, 0.5253]])\n",
            "D =  [[0.8479715  0.01936865 0.5424599 ]\n",
            " [0.33431488 0.14499027 0.22859651]\n",
            " [0.23097473 0.7568917  0.5253498 ]]\n",
            "E =  tensor([[[[1, 2, 3],\n",
            "          [4, 5, 6]]]])\n",
            "sum of A  =  tensor(0.)\n",
            "mean of A =  tensor(0.)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "## 실습 1 ##\n",
        "A = torch.tensor([[1., -1.], [1., -1.]])\n",
        "print('A = ', A)\n",
        "B = torch.tensor(np.array([[1,2,3],[4,5,6]]))\n",
        "print('B = ', B)\n",
        "\n",
        "C = torch.rand(3,3)\n",
        "print('C = ', C)\n",
        "\n",
        "D = C.numpy()\n",
        "print('D = ', D)\n",
        "\n",
        "E = B.view(1,1,2,3)\n",
        "print('E = ', E)\n",
        "\n",
        "print('sum of A  = ', A.sum())\n",
        "print('mean of A = ', A.mean())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "data = [[1,2],[3,4]]\n",
        "x_data = torch.tensor(data)\n",
        "\n",
        "import numpy as np\n",
        "np_array = np.array(data)\n",
        "tensor_from_numpy = torch.from_numpy(np_array)\n",
        "\n",
        "x_zeros = torch.zeros(2,3)\n",
        "x_ones = torch.ones(3,2)\n",
        "x_rand = torch.rand(2,2)\n",
        "\n",
        "random_uniform = torch.rand(3,3)\n",
        "int_tensor = torch.tensor([1,2,3])\n",
        "float_tensor = torch.tensor([1.0,2.0,3.0])\n",
        "tensor_a = torch.rand(3,3)\n",
        "ones_like_a = torch.ones_like(tensor_a)\n",
        "\n",
        "# Check if CUDA (GPU support) is available\n",
        "if torch.cuda.is_available():\n",
        "  # Create a tensor\n",
        "  tensor = torch.randn(3, 3) # Replace with your tensor\n",
        "  # Move the tensor to the GPU\n",
        "  tensor_gpu = tensor.to('cuda')\n",
        "  print(\"Tensor moved to GPU:\", tensor_gpu)\n",
        "else:\n",
        "  print(\"CUDA is not available. Tensor cannot be moved to GPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rULVvChiP3j",
        "outputId": "368dd8ea-c5c3-476e-ed28-74295299c613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor moved to GPU: tensor([[-1.1626, -0.1514, -0.2848],\n",
            "        [-0.7309,  0.0846,  2.4920],\n",
            "        [-0.9439,  0.2925, -0.2240]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Create a tensor and set requires_grad=True to track computation with it\n",
        "x = torch.tensor([2.0, 3.0, 4.0], requires_grad=True)\n",
        "# Define a quadratic function: y = 3 * (x ** 2)\n",
        "y = 3 * (x ** 2)\n",
        "# Compute the sum of y to create a scalar output\n",
        "z = y.sum()\n",
        "# Perform backpropagation to compute gradients of z with respect to x\n",
        "z.backward()\n",
        "# Print the computed gradients\n",
        "print(x.grad) # This should print the gradient at x = [2.0, 3.0, 4.0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9I86L-so2mB",
        "outputId": "47bac713-3a31-4aa2-eeb6-a052365fdff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([12., 18., 24.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.tensor([[2.]], requires_grad=True)  # leaf tensor\n",
        "print('x = ', x)\n",
        "print('x.data = ', x.data)\n",
        "print('x.grad = ', x.grad)\n",
        "print('x.grad_fn() = ', x.grad_fn)\n",
        "\n",
        "# 연산 수행\n",
        "y = x * x * 3  # non-leaf tensor\n",
        "y.retain_grad()  # non-leaf tensor의 grad 저장 활성화\n",
        "print('\\ny = ', y)\n",
        "print('y.data = ', y.data)\n",
        "print('y.grad = ', y.grad)  # 아직 None (역전파 전)\n",
        "print('y.grad_fn() = ', y.grad_fn)\n",
        "\n",
        "z = y ** 2  # non-leaf tensor\n",
        "z.retain_grad()  # non-leaf tensor의 grad 저장 활성화\n",
        "print('\\nz = ', z)\n",
        "print('z.data = ', z.data)\n",
        "print('z.grad = ', z.grad)  # 아직 None (역전파 전)\n",
        "\n",
        "# 역전파 수행\n",
        "z.backward()\n",
        "print('\\nAfter invocation of backward()')\n",
        "\n",
        "# leaf tensor\n",
        "print('\\nx = ', x)\n",
        "print('x.data = ', x.data)\n",
        "print('x.grad = ', x.grad)  # leaf tensor의 grad는 자동 계산됨\n",
        "print('x.grad_fn( ) = ', x.grad_fn)\n",
        "\n",
        "# non-leaf tensor\n",
        "print('\\ny = ', y)\n",
        "print('y.data = ', y.data)\n",
        "print('y.grad = ', y.grad)  # non-leaf tensor의 grad 접근 가능\n",
        "print('y.grad_fn( ) = ', y.grad_fn)\n",
        "\n",
        "print('\\nz = ', z)\n",
        "print('z.data = ', z.data)\n",
        "print('z.grad = ', z.grad)  # non-leaf tensor의 grad 접근 가능\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80AsWc5jo_W0",
        "outputId": "b9169147-572f-435d-c479-bacf34361d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x =  tensor([[2.]], requires_grad=True)\n",
            "x.data =  tensor([[2.]])\n",
            "x.grad =  None\n",
            "x.grad_fn() =  None\n",
            "\n",
            "y =  tensor([[12.]], grad_fn=<MulBackward0>)\n",
            "y.data =  tensor([[12.]])\n",
            "y.grad =  None\n",
            "y.grad_fn() =  <MulBackward0 object at 0x7eeca5997550>\n",
            "\n",
            "z =  tensor([[144.]], grad_fn=<PowBackward0>)\n",
            "z.data =  tensor([[144.]])\n",
            "z.grad =  None\n",
            "\n",
            "After invocation of backward()\n",
            "\n",
            "x =  tensor([[2.]], requires_grad=True)\n",
            "x.data =  tensor([[2.]])\n",
            "x.grad =  tensor([[288.]])\n",
            "x.grad_fn( ) =  None\n",
            "\n",
            "y =  tensor([[12.]], grad_fn=<MulBackward0>)\n",
            "y.data =  tensor([[12.]])\n",
            "y.grad =  tensor([[24.]])\n",
            "y.grad_fn( ) =  <MulBackward0 object at 0x7eeca5997910>\n",
            "\n",
            "z =  tensor([[144.]], grad_fn=<PowBackward0>)\n",
            "z.data =  tensor([[144.]])\n",
            "z.grad =  tensor([[1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "신경망 모델 구성"
      ],
      "metadata": {
        "id": "yrXZCbUsp0gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# Define the neural network class\n",
        "class SimpleNeuralNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(SimpleNeuralNet, self ).__init__()\n",
        "    # First fully connected layer\n",
        "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "    # Second fully connected layer that outputs our classes\n",
        "    self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "  def forward(self, x):\n",
        "    # Pass the input through the first layer, then apply a ReLU activation\n",
        "    x = F.relu(self.fc1(x))\n",
        "    # Pass the output through the second layer\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "# Define the size of our layers and number of classes\n",
        "input_size = 784 # Example for flattened 28x28 pixel image input\n",
        "hidden_size = 500 # Number of nodes in the hidden layer\n",
        "num_classes = 10 # Number of output classes (e.g., for digits 0-9)\n",
        "\n",
        "# Create an instance of our neural network\n",
        "model = SimpleNeuralNet(input_size, hidden_size, num_classes)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UADMGbuap2Tt",
        "outputId": "5113efad-141d-4426-be12-0682d5492191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleNeuralNet(\n",
            "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
            "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습가능 파라미터 확인"
      ],
      "metadata": {
        "id": "ZZiUAXagqHVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# Define a simple neural network\n",
        "class SimpleNet(nn.Module):\n",
        "  def __init__(self ):\n",
        "    super(SimpleNet, self ).__init__()\n",
        "    self.fc1 = nn.Linear(10, 5) # A fully connected layer\n",
        "    self.fc2 = nn.Linear(5, 2) # Another fully connected layer\n",
        "  def forward(self, x):\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "# Create an instance of the network\n",
        "net = SimpleNet()\n",
        "# Print the learnable parameters\n",
        "for param in net.parameters():\n",
        "  print(param)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JElKXum0qJ82",
        "outputId": "4cec6538-cff7-494d-886a-a57c7bbe7bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.3088, -0.3161, -0.2099, -0.1640,  0.2435, -0.1238, -0.1802,  0.3051,\n",
            "          0.2772,  0.3115],\n",
            "        [-0.2406,  0.0573,  0.0244,  0.2363,  0.2835,  0.2885,  0.2706,  0.0533,\n",
            "         -0.0843,  0.1962],\n",
            "        [-0.2198,  0.3049,  0.3017,  0.1725, -0.1607, -0.1312, -0.2123,  0.1600,\n",
            "          0.0426,  0.2099],\n",
            "        [-0.2207, -0.0527, -0.0791, -0.0787, -0.2665,  0.0383, -0.2442,  0.2693,\n",
            "         -0.0896,  0.2318],\n",
            "        [-0.1468, -0.0922, -0.2152, -0.1916,  0.0581, -0.2412,  0.0467,  0.2328,\n",
            "         -0.1083,  0.2134]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.1360, -0.1980, -0.0432,  0.1540,  0.0453], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.2062,  0.3697,  0.4335,  0.1920,  0.1053],\n",
            "        [-0.2307, -0.1255, -0.1183, -0.3160,  0.2100]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2748, -0.1908], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습된 모델 저장"
      ],
      "metadata": {
        "id": "5vyKiBZAqYrk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNet(nn.Module):\n",
        "  def __init__(self ):\n",
        "    super(SimpleNet, self ).__init__()\n",
        "    self.fc1 = nn.Linear(10, 5)\n",
        "    self.fc2 = nn.Linear(5, 2)\n",
        "  def forward(self, x):\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "# Create an instance of the network (example)\n",
        "net = SimpleNet()\n",
        "# Assuming the model is trained here\n",
        "# ...\n",
        "# Save the model's state dictionary\n",
        "torch.save(net.state_dict(), 'model_weights.pth')\n",
        "print(\"Model's state dict saved as 'model_weights.pth'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGvlqBdVqcZ1",
        "outputId": "d731b498-3840-40fe-e2c4-e59e9cd53598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's state dict saved as 'model_weights.pth'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "저장된 모델 적재"
      ],
      "metadata": {
        "id": "O9wkJCSvqlEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "class SimpleNet(nn.Module):\n",
        "  def __init__(self ):\n",
        "    super(SimpleNet, self ).__init__()\n",
        "    self.fc1 = nn.Linear(10, 5)\n",
        "    self.fc2 = nn.Linear(5, 2)\n",
        "  def forward(self, x):\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "# 먼저 모델 객체 생성\n",
        "net = SimpleNet()\n",
        "# Load the saved state_dict\n",
        "net.load_state_dict(torch.load('model_weights.pth', weights_only=True))\n",
        "# If you are loading the model for inference (not training), set to eval mode\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH-X5CqVqmRO",
        "outputId": "9c7f79d2-615b-4fd7-b27a-c7442f6518ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleNeuralNet(\n",
              "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
              "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataSet과 DataLoader"
      ],
      "metadata": {
        "id": "FQu6Rpfqq9km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# Example custom dataset\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, data, labels):\n",
        "    self.data = data\n",
        "    self.labels = labels\n",
        "  def __len__(self ):\n",
        "    return len(self.data)\n",
        "  def __getitem__(self, index):\n",
        "    return self.data[index], self.labels[index]\n",
        "# Sample data\n",
        "data = torch.randn(100, 10) # 100 samples, 10 features each\n",
        "labels = torch.randint(0, 2, (100,)) # 100 labels (binary classification)# Create dataset\n",
        "dataset = CustomDataset(data, labels)\n",
        "# Create DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "# Iterate through the DataLoader\n",
        "for batch in dataloader:\n",
        "  batch_data, batch_labels = batch # Perform operations on batch_data and batch_labels"
      ],
      "metadata": {
        "id": "APPCpK4Pq9Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 학습 및 추론"
      ],
      "metadata": {
        "id": "QrBfihB2rOJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# Define a simple model\n",
        "class SimpleModel(nn.Module):\n",
        "  def __init__(self ):\n",
        "    super(SimpleModel, self ).__init__()\n",
        "    self.fc1 = nn.Linear(10, 50)\n",
        "    self.dropout = nn.Dropout(0.25)\n",
        "    self.fc2 = nn.Linear(50, 2)\n",
        "  def forward(self, x):\n",
        "    x = torch.relu(self.fc1(x))\n",
        "    x = self.dropout(x)\n",
        "    # Dropout during training\n",
        "    return x\n",
        "model = SimpleModel()\n",
        "\n",
        "# 손실함수와 optimizer\n",
        "Criterion = nn.CrossEntropyLoss()\n",
        "Optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "# 학습데이터 (inputs and labels)\n",
        "Inputs = torch.randn(5, 10) # 10개 입력 속성의 5개 데이터\n",
        "labels = torch.randint(0, 2, (5,)) # 이진 분류 출력\n",
        "# 학습모드 설정\n",
        "model.train()\n",
        "for epoch in range(5): # epoch 수\n",
        "  Optimizer.zero_grad() # 파라미터 그레디언트 0 초기화\n",
        "  # forward pass\n",
        "  outputs = model(Inputs)\n",
        "  loss = Criterion(outputs, labels)\n",
        "  # backward pass + optimize\n",
        "  loss.backward() # 그레디언트 개산\n",
        "  Optimizer.step() # 가중치 갱신\n",
        "# 추론모드 설정\n",
        "model.eval()\n",
        "with torch.no_grad(): # 그레디언트 미계산\n",
        "  outputs = model(Inputs)"
      ],
      "metadata": {
        "id": "MLJ9JuJ4rQCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " PyTorch의 MLP 프로그래밍\n"
      ],
      "metadata": {
        "id": "aWCLbr1Rrqbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#_*_ coding: utf-8 _*_\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "\n",
        "X = mnist.data/255\n",
        "y = mnist.target\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X.iloc[0].values.reshape(28,28), cmap='gray') # X.iloc[0]로 첫 번째 행을 선택하고 .values로 NumPy 배열로 변환합니다.\n",
        "plt.show()\n",
        "print(\"이미지 레이블: {}\".format(y[0]))\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 1/7, random_state = 0)\n",
        "X_train  = torch.Tensor(X_train.values)\n",
        "X_test = torch.Tensor(X_test.values)\n",
        "y_train = torch.LongTensor(list(map(int, y_train)))\n",
        "y_test = torch.LongTensor(list(map(int, y_test)))\n",
        "\n",
        "ds_train = TensorDataset(X_train, y_train)\n",
        "ds_test = TensorDataset(X_test, y_test)\n",
        "\n",
        "loader_train = DataLoader(ds_train, batch_size=64, shuffle=True)\n",
        "loader_test = DataLoader(ds_test, batch_size=64, shuffle=False)\n",
        "\n",
        "from torch import nn\n",
        "model = nn.Sequential()\n",
        "model.add_module('fc1', nn.Linear(28*28*1, 100))\n",
        "model.add_module('relu1', nn.ReLU())\n",
        "model.add_module('fc2', nn.Linear(100, 100))\n",
        "model.add_module('relu2', nn.ReLU())\n",
        "model.add_module('fc3', nn.Linear(100, 10))\n",
        "\n",
        "from torch import optim\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  for data, targets in loader_train:\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(data)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print('에포크 {}: 완료'.format(epoch))\n",
        "\n",
        "def test(head):\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for data, targets in loader_test:\n",
        "      outputs = model(data)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      correct += predicted.eq(targets.data.view_as(predicted)).sum()\n",
        "    data_num = len(loader_test.dataset)\n",
        "    print('{} 정확도: {}/{} ({:.0f}%)'.format(head, correct, data_num, 100. * correct / data_num))\n",
        "\n",
        "test('시작')\n",
        "for epoch in range(3):\n",
        "  train(epoch)\n",
        "  test('학습중')\n",
        "test('학습후')\n",
        "\n",
        "index = 10\n",
        "model.eval()\n",
        "data = X_test[index]\n",
        "output = model(data)\n",
        "print('{} 번째 학습 데이터의 테스트 결과 : {}'.format(index, output))\n",
        "_, predicted = torch.max(output.data, 0)\n",
        "print('{} 번째 데이터의 예측: {}'.format(index, predicted))\n",
        "X_test_show = (X_test[index]).numpy()\n",
        "plt.imshow(X_test_show.reshape(28,28), cmap='gray')\n",
        "print('실제 레이블: {}'.format(y_test[index]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7gFXImF-rtSE",
        "outputId": "3fbb2856-0459-460c-8f70-048857838511"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "이미지 레이블: 5\n",
            "시작 정확도: 851/10000 (9%)\n",
            "에포크 0: 완료\n",
            "학습중 정확도: 9416/10000 (94%)\n",
            "에포크 1: 완료\n",
            "학습중 정확도: 9552/10000 (96%)\n",
            "에포크 2: 완료\n",
            "학습중 정확도: 9543/10000 (95%)\n",
            "학습후 정확도: 9543/10000 (95%)\n",
            "10 번째 학습 데이터의 테스트 결과 : tensor([-2.6341, 11.5339, -5.2136, -2.8809, -0.9954, -5.7306, -4.0908, -8.3414,\n",
            "         1.2382, -5.1854], grad_fn=<ViewBackward0>)\n",
            "10 번째 데이터의 예측: 1\n",
            "실제 레이블: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[실습] CNN 모델을 이용한 MNIST 데이터 분류"
      ],
      "metadata": {
        "id": "58KfA0khv5Fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "\n",
        "X = mnist.data/255\n",
        "y = mnist.target\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size= 1/7, random_state=0)\n",
        "X_train = torch.Tensor(X_train.values)\n",
        "X_test = torch.Tensor(X_test.values)\n",
        "y_train = torch.LongTensor(list(map(int, y_train)))\n",
        "y_test = torch.LongTensor(list(map(int, y_test)))\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "X_train = X_train.view(-1,1,28,28).float()\n",
        "X_test = X_test.view(-1,1,28,28).float()\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "train = TensorDataset(X_train, y_train)\n",
        "test = TensorDataset(X_test, y_test)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1,32, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(32,32, kernel_size=5)\n",
        "    self.conv3 = nn.Conv2d(32,64, kernel_size=5)\n",
        "    self.fn1 = nn.Linear(3*3*64, 256)\n",
        "    self.fn2 = nn.Linear(256, 10)\n",
        "\n",
        "    self.loss_fn = nn.CrossEntropyLoss()\n",
        "    self.optimizer = optim.Adam(self.parameters(), lr=0.01)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
        "    x = F.dropout(x, p=0.5, training=self.training)\n",
        "    x = F.relu(F.max_pool2d(self.conv3(x),2))\n",
        "    x = F.dropout(x, p=0.5, training=self.training)\n",
        "    x = x.view(-1,3*3*64)\n",
        "    x = F.relu(self.fn1(x))\n",
        "    x = F.dropout(x, training=self.training)\n",
        "    x = self.fn2(x)\n",
        "    return F.log_softmax(x, dim = 1)\n",
        "\n",
        "def fit(model, loader_train):\n",
        "  optimizer = torch.optim.Adam(model.parameters())\n",
        "  error = nn.CrossEntropyLoss()\n",
        "  EPOCHS = 1\n",
        "  model.train()\n",
        "  for epoch in range(EPOCHS):\n",
        "    correct = 0\n",
        "    for batch_idx, (X_batch, y_batch) in enumerate(loader_train):\n",
        "      # Reshape X_batch to have the correct dimensions for the convolutional layer\n",
        "      var_X_batch = Variable(X_batch.view(-1, 1, 28, 28)).float()  # Reshape to [batch_size, channels, height, width]\n",
        "      var_y_batch = Variable(y_batch)\n",
        "      optimizer.zero_grad()\n",
        "      output = model(var_X_batch)\n",
        "      loss = error(output, var_y_batch)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      predicted = torch.max(output.data, 1)[1]\n",
        "      correct += (predicted == var_y_batch).sum()\n",
        "      if batch_idx % 50 == 0:\n",
        "        print('에포크 : {} [{}/{} ({:.0f}%)]\\t 손실함수 : {:.6f}\\t Accuracy:{:.3f}%'.format(epoch, batch_idx*len(var_X_batch), len(loader_train.dataset), 100.*batch_idx / len(loader_train), loss.data, float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))\n",
        "def evaluate(model):\n",
        "  correct = 0\n",
        "  for test_imgs, test_labels in loader_test:\n",
        "    # Reshape test_imgs to have the correct dimensions for the convolutional layer\n",
        "    test_imgs = test_imgs.view(-1, 1, 28, 28).float()  # Reshape to [batch_size, channels, height, width]\n",
        "    test_imgs = Variable(test_imgs).float()\n",
        "    output = model(test_imgs)\n",
        "    predicted = torch.max(output,1)[1]\n",
        "    correct += (predicted == test_labels).sum()\n",
        "\n",
        "  print(\"테스트 데이터 정확도 : {:.3f}% \".format(float(correct)/(len(loader_test)*BATCH_SIZE)))\n",
        "\n",
        "cnn = CNN()\n",
        "evaluate(cnn)\n",
        "fit(cnn, loader_train)\n",
        "cnn.eval()\n",
        "evaluate(cnn)\n",
        "index = 10\n",
        "data = X_test[index].view(-1,1,28,28).float()\n",
        "output = cnn(data)\n",
        "print('{} 번째 학습 데이터의 테스트 결과 : {}'.format(index, output))\n",
        "_, predicted = torch.max(output.data, 1)\n",
        "print('{} 번째 데이터의 예측: {}'.format(index, predicted.numpy()))\n",
        "print('실제 레이블: {}'.format(y_test[index]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcg7ic1bv41_",
        "outputId": "0638814b-a025-417e-c928-80fe811a3927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60000, 1, 28, 28])\n",
            "torch.Size([10000, 1, 28, 28])\n",
            "테스트 데이터 정확도 : 0.196% \n",
            "에포크 : 0 [0/60000 (0%)]\t 손실함수 : 2.310141\t Accuracy:12.500%\n",
            "에포크 : 0 [3200/60000 (5%)]\t 손실함수 : 0.941365\t Accuracy:83.640%\n",
            "에포크 : 0 [6400/60000 (11%)]\t 손실함수 : 0.285991\t Accuracy:122.401%\n",
            "에포크 : 0 [9600/60000 (16%)]\t 손실함수 : 0.258957\t Accuracy:140.252%\n",
            "에포크 : 0 [12800/60000 (21%)]\t 손실함수 : 0.248562\t Accuracy:150.451%\n",
            "에포크 : 0 [16000/60000 (27%)]\t 손실함수 : 0.382346\t Accuracy:157.034%\n",
            "에포크 : 0 [19200/60000 (32%)]\t 손실함수 : 0.267048\t Accuracy:161.856%\n",
            "에포크 : 0 [22400/60000 (37%)]\t 손실함수 : 0.127414\t Accuracy:165.037%\n",
            "에포크 : 0 [25600/60000 (43%)]\t 손실함수 : 0.113503\t Accuracy:167.807%\n",
            "에포크 : 0 [28800/60000 (48%)]\t 손실함수 : 0.184713\t Accuracy:170.039%\n",
            "에포크 : 0 [32000/60000 (53%)]\t 손실함수 : 0.197293\t Accuracy:171.831%\n",
            "에포크 : 0 [35200/60000 (59%)]\t 손실함수 : 0.039727\t Accuracy:173.350%\n",
            "에포크 : 0 [38400/60000 (64%)]\t 손실함수 : 0.217560\t Accuracy:174.558%\n",
            "에포크 : 0 [41600/60000 (69%)]\t 손실함수 : 0.176676\t Accuracy:175.826%\n",
            "에포크 : 0 [44800/60000 (75%)]\t 손실함수 : 0.303018\t Accuracy:176.921%\n",
            "에포크 : 0 [48000/60000 (80%)]\t 손실함수 : 0.074634\t Accuracy:177.855%\n",
            "에포크 : 0 [51200/60000 (85%)]\t 손실함수 : 0.104966\t Accuracy:178.687%\n",
            "에포크 : 0 [54400/60000 (91%)]\t 손실함수 : 0.227931\t Accuracy:179.355%\n",
            "에포크 : 0 [57600/60000 (96%)]\t 손실함수 : 0.227385\t Accuracy:180.022%\n",
            "테스트 데이터 정확도 : 1.946% \n",
            "10 번째 학습 데이터의 테스트 결과 : tensor([[-1.3430e+01, -9.5363e-05, -1.3085e+01, -1.8130e+01, -9.6006e+00,\n",
            "         -1.4560e+01, -1.4255e+01, -1.1063e+01, -1.2771e+01, -1.2304e+01]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "10 번째 데이터의 예측: [1]\n",
            "실제 레이블: 1\n"
          ]
        }
      ]
    }
  ]
}